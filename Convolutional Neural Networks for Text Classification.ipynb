{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Text Classification\n",
    "CNNs are typically associated with computer vision. They have been shown to offer dramatic improvements in image classification, as shown by ImageNet.\n",
    "\n",
    "CNNs can also be used for some NLP tasks, particularly text classification, which is the task of classifying texts into two or more categories. Although they haven't given the same boost in performance to NLP as they have to computer vision, they can still be used as an effective machine learning algorithm. In this notebook, we will:\n",
    "\n",
    "* Look at a popular (non-biomedical)* dataset and NLP task\n",
    "* Train a CNN for sentiment analysis\n",
    "* Compare a CNN using pretrained word embeddings\n",
    "\n",
    "\\* Note: Deep learning models need lots of data. Since this is a supervised task, we need lots of *labeled* data. For this reason, we aren't going to be using Biomedical tasks as examples, but the concepts can be transferred to any field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment Analysis - IMDB Dataset\n",
    "*Sentiment Analysis* is a popular NLP classification task. In sentiment analysis, we are looking at a piece of text and trying to determine what emotion the text is expressing. It is often binary, which means a text can be either **positive** or **negative**.\n",
    "\n",
    "Reviews are an excellent example of texts that can be used for this task. A popular dataset is the IMDB dataset, which has 50,000 movie reviews, split between positive and negative. Our task will be to predict whether a review is positive (the reviewer liked the movie) or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "MAX_FEATURES = 10000 # Number of words to consider as features\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what our data looks like. First, here's what it looks like when we load it from keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y` is fairly straightforward: 0 means negative and 1 means positive. But what does x mean? \n",
    "\n",
    "Let's consider the first data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = x_train[0]\n",
    "print(len(x0))\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of x is a list of integers. The first row has a length of 106. What do these integers mean?\n",
    "\n",
    "Each number is the index for a particular word. A text is transformed from strings to integers. Remember how we limited our number of features to 10,000 words? That's the length of our vocabulary, and any words outside of that vocabulary will just be ignored.\n",
    "\n",
    "Each list of numbers is called a **sequence**, and sequences are primarily what we'll be dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "print(len(word_index))\n",
    "for word in ['hello', 'world']:\n",
    "    print(word, word_index[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "reverse_word_index.get('?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what the data actually looks like. Before we loaded the data, the string reports had already been preprocessed and mapped from strings (words) to integers (indices). To see the data in a (somewhat) human-readable form, we'll write a function `inverse_transform` that reverses this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(seq, word_index):\n",
    "    # word_index is a dictionary mapping words to an integer index\n",
    "    # We reverse it, mapping integer indices to words\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "    # We decode the review; note that our indices were offset by 3\n",
    "    # because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "\n",
    "    \n",
    "    decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in seq])\n",
    "    \n",
    "    return decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_idx = list(y_train).index(0)\n",
    "pos_idx = list(y_train).index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a positive review\n",
    "negative_decoded_review = inverse_transform(x_train[neg_idx], word_index)\n",
    "    \n",
    "# And a negative review\n",
    "positive_decoded_review = inverse_transform(x_train[pos_idx], word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(negative_decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positive_decoded_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. More Data Processing\n",
    "\n",
    "As part of the next step, we'll do a bit more data processing.\n",
    "\n",
    "The first thing to consider is how long each sequence is. With our Cats vs. Dogs classifier, each image was resized to be the same size and shape. Keras expects data to be formatted like this. Let's look at how long our reviews are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "review_lengths = [len(row) for row in x_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean: {}\".format(np.mean(review_lengths)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(review_lengths)))\n",
    "print(\"Max: {}\".format(max(review_lengths)))\n",
    "print(\"Min: {}\".format(min(review_lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(review_lengths, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, most reviews are around 200 words long. There's a long tail of some more long-winded reviews, and a few very short ones as well.\n",
    "\n",
    "We'll have to normalize the sequences so that each one is the same length. We'll do this two ways: for long reviews, we'll cut them down using the parameter `MAX_SEQUENCE_LENGTH`, and for any reviews shorter than that number, we'll \"pad\" them by adding 0's to the beginning of those shorter reviews: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "MAX_FEATURES = 10000 # number of words to consider as features\n",
    "MAX_SEQUENCE_LENGTH = 500 # cut texts after this number of words (among top max_features most common words)\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sequence is now only 500 words long. Let's look at what our earlier negative review looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inverse_transform(x_train[0], word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what the longest review looks like:\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Train a CNN for Sentiment Analysis\n",
    "\n",
    "TODO: Do some descriptions of what CNNs for text look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "callbacks = [TensorBoard('./logs', batch_size=BATCH_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential(name='model_no_pretrained_embeddings')\n",
    "model.add(Embedding(input_dim=MAX_FEATURES,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "#                     batch_size=BATCH_SIZE,\n",
    "                    input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    " loss='binary_crossentropy',\n",
    " metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                  validation_data=(x_test, y_test),\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the Cats vs. Dogs notebook, we're going to load a pretrained model  and training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('saved_models/imdb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history\n",
    "import pickle\n",
    "with open('logs/imdb_history.pkl', 'rb') as f:\n",
    "    h = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(h['acc'], marker='.', linestyle='dotted', alpha=0.4, label='IMDB Training Acc')\n",
    "plt.plot(h['val_acc'], marker='.', label=\"IMDB Validation Acc\")\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylim((0.5, 0.92))\n",
    "plt.legend(loc='upper center', ncol=2,mode='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name='model_4_epochs')\n",
    "model.add(Embedding(input_dim=MAX_FEATURES,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "#                     batch_size=BATCH_SIZE,\n",
    "                    input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    " loss='binary_crossentropy',\n",
    " metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=4, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                  validation_data=(x_test, y_test),\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index.get(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/imdb_4_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('saved_models/imdb_4_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try predicting our own movie reviews:\n",
    "from nltk.tokenize import word_tokenize\n",
    "def classify_reviews(texts, model):\n",
    "    x = np.array([prepare_text(text) for text in texts])\n",
    "    x = sequence.pad_sequences(x, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    return model.predict_classes(x)\n",
    "    return seq\n",
    "\n",
    "def prepare_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    seq = words2seq(tokens)\n",
    "    \n",
    "    return seq\n",
    "\n",
    "def words2seq(words):\n",
    "    seq = []\n",
    "    for w in words:\n",
    "        idx = word_index.get(w)\n",
    "        if idx is not None and idx < MAX_FEATURES:  # 2 is the placeholder for out-of-vocabulary\n",
    "            seq.append(idx + 3)\n",
    "        else:\n",
    "            seq.append(2)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_mamma_mia = \"\"\"\n",
    "Even better than the original, creating a great backstory and bringing a touching and gratifying closure to the \\\n",
    "mother-daughter story of Mamma Mia. Excellent choreography, catchy songs and beautiful performances by Lilly James and \\\n",
    "Amanda Seyfried, plus just the right amount of humor and sentimentality.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mamma_mia = \"\"\"\n",
    "As a film, it was overly reliant on the audiences nostalgia, incorporating the lower quality Abba songs which \\\n",
    "remind you how much more you wanted to watch the original. The original Swedish script echoes in this, with much \\\n",
    "of the dialogue being poorly localised and therefore making very little sense at all. \\\n",
    "A very basic and safe plot is used, making it evident that this film was only made as a cash grab from a fanbase still \\\n",
    "in love with the original\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_reviews([positive_mamma_mia, negative_mamma_mia],\n",
    "                model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Add pretrained word embedings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_PATH = '/Users/alec/Data/glove.6B/glove.6B.200d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(EMBEDDINGS_PATH)\n",
    "embeddings_index = {}\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((MAX_FEATURES, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < MAX_FEATURES:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index.get('movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model w/ Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Flatten, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "# from kears.layers import \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something's not right here\n",
    "model_pretrained_emb = Sequential(name='model_pretrained_embeddings')\n",
    "model_pretrained_emb.add(\n",
    "    Embedding(input_dim=MAX_FEATURES,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_pretrained_emb.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model_pretrained_emb.add(layers.MaxPooling1D(5))\n",
    "model_pretrained_emb.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model_pretrained_emb.add(layers.MaxPooling1D(5))\n",
    "model_pretrained_emb.add(Flatten())\n",
    "model_pretrained_emb.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_pretrained_emb.compile(optimizer=RMSprop(lr=1e-4),\n",
    " loss='binary_crossentropy',\n",
    " metrics=['acc'])\n",
    "history_pretrained_emb = model_pretrained_emb.fit(x_train, y_train,\n",
    "                         validation_data=(x_test, y_test),\n",
    "                         epochs=10, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pre = model_pretrained_emb.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained_emb.save('saved_models/imdb_pretrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/history_pretrained.pkl', 'wb') as f:\n",
    "    pickle.dump(h_pre, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pre = history_pretrained_emb.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {'imdb': h,\n",
    "            'imdb_pretrained': h_pre}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_scores(histories):\n",
    "fig, ax = plt.subplots()\n",
    "x = range(10)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "i = 0\n",
    "for name, history in histories.items():\n",
    "    ax.plot(history['acc'], marker='.', linestyle='dotted', label=\"{} train acc\".format(name, alpha=0.4), color=colors[i])\n",
    "    ax.plot(history['val_acc'], marker='.', label=\"{} val acc\".format(name))\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "# ax.set_title('CNN Sentiment Analysis Validation Accuracy')\n",
    "ax.set_xlabel('# epochs')\n",
    "fig.legend(loc='upper center', ncol=2,mode='expand')\n",
    "\n",
    "\n",
    "\n",
    "# plot_scores(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare a Traditional Machine Learning Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqs2bow(x, vectorizer=None):\n",
    "    \"\"\"\n",
    "    Takes a list of sequences\n",
    "    and converts them into a bag of words vector.\n",
    "    \"\"\"\n",
    "    x_dicts = []\n",
    "    for seq in x:\n",
    "        d = {}\n",
    "        for word in seq:\n",
    "            if word not in d:\n",
    "                d[word] = 0\n",
    "            d[word] += 1\n",
    "        x_dicts.append(d)\n",
    "        \n",
    "    if not vectorizer:\n",
    "        vectorizer = DictVectorizer()\n",
    "        x = vectorizer.fit_transform(x_dicts)\n",
    "    else:\n",
    "        x = vectorizer.transform(x_dicts)\n",
    "    \n",
    "    return x, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new, vectorizer = seqs2bow(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_new, vectorizer = seqs2bow(x_test, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = clf.predict(x_train_new)\n",
    "bow_train_acc = accuracy_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(x_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "bow_val_acc = accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_scores(histories):\n",
    "fig, ax = plt.subplots()\n",
    "x = range(10)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "i = 0\n",
    "for name, history in histories.items():\n",
    "    ax.plot(history['acc'], marker='.', linestyle='dotted', label=\"{} train acc\".format(name, alpha=0.4), color=colors[i])\n",
    "    ax.plot(history['val_acc'], marker='.', label=\"{} val acc\".format(name))\n",
    "    i += 1\n",
    "    \n",
    "# Add a horizontal line showing the BOW accuracy\n",
    "ax.hlines(y=bow_train_acc, xmin=0, xmax=10, label='BOW training accuracy', color=colors[i], linestyle='dotted')\n",
    "ax.hlines(y=bow_val_acc, xmin=0, xmax=10, label='BOW validation accuracy', color=colors[i], alpha=0.4)\n",
    "    \n",
    "# ax.set_title('CNN Sentiment Analysis Validation Accuracy')\n",
    "ax.set_xlabel('# epochs')\n",
    "fig.legend(loc='upper center', ncol=3,mode='expand')\n",
    "\n",
    "\n",
    "\n",
    "# plot_scores(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def score_table():\n",
    "    df = pd.DataFrame(columns=['Model Name', 'Max Training Accuracy', 'Max Validation Accuracy'],\n",
    "                     data=[\n",
    "                         {'Model Name': \"IMDB\", \n",
    "                          \"Max Training Accuracy\": max(histories['imdb']['acc']),\n",
    "                          'Max Validation Accuracy': max(histories['imdb']['val_acc'])\n",
    "                         },\n",
    "                     {\"Model Name\":'IMDB Pretrained Embeddings', \n",
    "                     \"Max Training Accuracy\": max(histories['imdb_pretrained']['acc']),\n",
    "                     \"Max Validation Accuracy\": max(histories['imdb_pretrained']['val_acc'])},\n",
    "                     {'Model Name': 'Random Forest BOW',\n",
    "                     \"Max Training Accuracy\": bow_train_acc,\n",
    "                      \"Max Validation Accuracy\": bow_val_acc\n",
    "                     }])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
